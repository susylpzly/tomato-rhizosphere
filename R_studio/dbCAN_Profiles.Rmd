---
title: "Functional_Profiles"
author: "Susana Lopez Lemarroy"
date: "2022-10-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Functional Profile Analysis of Shotgun Metagenome sequencing dataset, from strigolactone-deficient tomato rhizosphere samples
- 54 samples.
- 6 treatment groups: 3 experimental and 3 controls. 
- 12669 functional groups (PFAM families).
- data: mapped count reads from aligning sequenced reads back to assembled contigs, from *de novo* assembly. 


```{r}
#load PACKAGES
library(ggplot2)
library(vegan)
library(cluster)
library(compositions)
library(ape)
library(robCompositions)
library(dplyr)
library(tidyr)
library(parallel)
library(ggfortify)
library(phyloseq)
library(microbiome)
```


```{r}
#read the functional profile table 
df_counts <- read.csv("dbCAN_profile.csv", row.names = 'X')

#change NA values from empty spaces to 0 values
df_counts[is.na(df_counts)] <- 0

#sort the rows and columns by alphabetical order
df_counts <- df_counts[order(rownames(df_counts)),order(colnames(df_counts))]

#transform dataframe to make it data sciency format 
df_datascience <- as.data.frame(t(df_counts))
```

```{r}
#make a dataframe with only the sample names and change the column name to Sample 
df_info <- as.data.frame(colnames(df_counts)) %>% 
  'colnames<-'(c('Sample'))

#make Treatment column based on the Sample name, which includes the type of treatment 
df_info <- separate(df_info, Sample, into=c('t','Treatment','sample'), sep='[_]', remove = FALSE) %>% select(c(Sample,Treatment))
```

*THIS ALSO MADE THE INFO DATAFRAME BUT A BIT MORE COMPLICATED*
treatments_df <- as.data.frame(colnames(df_counts))
treatments_df <- treatments_df %>% 
  mutate(Treatment = case_when(
    grepl("712", `colnames(df_counts)`, fixed = TRUE) ~ "712",
    grepl("722", `colnames(df_counts)`, fixed = TRUE) ~ "722",
    grepl("CCD8", `colnames(df_counts)`, fixed = TRUE) ~ "CCD8",
    grepl("MMA", `colnames(df_counts)`, fixed = TRUE) ~ "MMA",
    grepl("GUS", `colnames(df_counts)`, fixed = TRUE) ~ "GUS",
    grepl("EP", `colnames(df_counts)`, fixed = TRUE) ~ "EP",
  )) %>%
  'colnames<-' c("Sample", "Treatment")


##ANALYSE FUNCTIONAL PROFILES 

-Filter by treatment type within functional group and then by general functional group 

##FOR GENERAL FILTERING

-for all the treatment types of a functional group's counts 
-if 70% of the counts are 0s (so 30% in the df_percent), then mark it as FALSE, otherwise mark it as TRUE (aggregate)
  -if half of the treatment types are TRUE then keep the functional group, else, eliminate it (by adding the name of the functional group to a list, which will then be used to eliminate those columns from the original df)
  -(maybe do this by counting the number of TRUES from the previous if and if there are 3 or more TRUEs then keep the functional group)
  
```{r}
#FILTERING FUNCTION: removes zero heavy functional groups from dataframe by counting percentage of zeros within treatment groups 
#and between treatment groups for each functional group 
#ARGUMENTS
#x = dataframe 
#treat_group_factor = treatment groups from info df, as df_info$Treatment
#per_treat_cutoff = number/percentage of treatment groups that have less than this value of 0s overall 

#funct_cutoff = 
filter_fun <- function(x,treat_group_factor,per_treat_cutoff,funct_cutoff){
  
#gets the decimal(percentage) of 0 values on functional groups for grouped treatment types. returns a df with grouped treatments
#on rows and functional groups on columns with percentage as values
perc0_funct <- aggregate(t(x),
                          list(treat_group_factor),
                          function(x) length(which(x==0))/length(x))

#per column (2) in the aggregation of how many 0's there are per functional group (perc0_groups[,-1]), 
#it counts (length) the number of treatment groups that have less than 30% (or given per_treat_cutoff) 0s 
#(which(x<0.3) and returns that number divided by the number of groups (length(x)
perc0_funct_all <- apply(perc0_funct[,-1],
                          2,
                          function(x) length(which(x<per_treat_cutoff))/length(x))

#which functional groups have more than a certain amount of treatment groups, with the treatment 0s count cutoff.
#get the functional groups that have more than the funct_cutoff of the treatment groups with a 0 average below the per_treat_cutoff
which(perc0_funct_all>funct_cutoff)
}
```


```{r}
#for a 0 count cutoff within treatments of 25% and a functional group treatment cutoff of 75% (at least 75% of treatment groups
#have enough 0s, less than 25%)
df_few0_funct <- df_counts[filter_fun(df_counts,df_info$Treatment, 0.25, 0.75),]

```

##FOR MAKING PAIRWISE DATAFRAMES WITH ONE TREATMENT VS ONE CONTROL DATAFRAMES 

- if making separate dataframes from zero counts, then match TRUEs from one experimental to one control and keep those functional groups in common (is this too many DFs?) 
- initialize a df (example: 712_MMA_df)
- make functional groups to remove list: if both of these treatment types have TRUEs for the previous filter of 30% 0s threshold, then add that functional group to the list (or should a different scheme be used?) 

```{r}
#Generating specific dataframes for pairs of treatment group comparisons 

#one Treatment with one Control 
#712-GUS
df_712_GUS <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(1,5)]]
df_few0_712_GUS <- df_712_GUS[filter_fun(df_712_GUS,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(1,5)]],0.25, 0.75),]
df_info_712_GUS <- df_info[df_info$Treatment=='712' | df_info$Treatment=='GUS',]

#712-MMA
df_712_MMA <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(1,6)]]
df_few0_712_MMA <- df_712_MMA[filter_fun(df_712_MMA,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(1,6)]],0.25, 0.75),]

#712_EP
df_712_EP <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(1,4)]]
df_few0_712_EP <- df_712_EP[filter_fun(df_712_EP,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(1,4)]],0.25, 0.75),]



#722-GUS
df_722_GUS <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(2,5)]]
df_few0_722_GUS <- df_722_GUS[filter_fun(df_722_GUS,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(2,5)]],0.25, 0.75),]

#722-MMA
df_722_MMA <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(2,6)]]
df_few0_722_MMA <- df_722_MMA[filter_fun(df_722_MMA,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(2,6)]],0.25, 0.75),]

#722_EP
df_722_EP <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(2,4)]]
df_few0_722_EP <- df_722_EP[filter_fun(df_722_EP,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(2,4)]],0.25, 0.75),]



#CCD8-GUS
df_CCD8_GUS <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(3,5)]]
df_few0_CCD8_GUS <- df_CCD8_GUS[filter_fun(df_CCD8_GUS,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(3,5)]],0.25, 0.75),]

#CCD8-MMA
df_CCD8_MMA <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(3,6)]]
df_few0_CCD8_MMA <- df_CCD8_MMA[filter_fun(df_CCD8_MMA,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(3,6)]],0.25, 0.75),]

#CCD8_EP
df_CCD8_EP <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(3,4)]]
df_few0_CCD8_EP <- df_CCD8_EP[filter_fun(df_CCD8_EP,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(3,4)]],0.25, 0.75),]



#2 Controls 
#GUS-MMA 
df_GUS_MMA <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(5,6)]]
df_few0_GUS_MMA <- df_GUS_MMA[filter_fun(df_GUS_MMA,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(5,6)]],0.25, 0.75),]


#all but EP
df_all_plant <- df_counts[,df_info$Treatment %in% unique(df_info$Treatment)[c(1,2,3,5,6)]]
df_few0_plant <- df_all_plant[filter_fun(df_all_plant,df_info$Treatment[df_info$Treatment %in% unique(df_info$Treatment)[c(1,2,3,5,6)]],0.25, 0.75),]
df_info_plant <- df_info[df_info$Treatment!= 'EP',]

```


# VIGS dataset with strigolactones concentrations information 
```{r}
VIGS_meta <- read.csv("VIGS_meta.csv")
VIGS_meta <- subset(VIGS_meta, select = -c(X))
```

```{r}
#make a dataframe with only the sample names and change the column name to Sample 
sInfo <- data.frame("sampleID"=colnames(df_counts))
sInfo$group <- gsub("_[^_]+$","",sInfo$sampleID)
sInfo <- sInfo[order(rownames(sInfo)),]
rownames(sInfo) <- sInfo$sampleID
```


```{r}
VIGS <- VIGS_meta[VIGS_meta$Sample_ID %in% sInfo$sampleID,]
VIGS <- VIGS[order(VIGS$Sample_ID),]
rownames(VIGS) <- VIGS$Sample_ID
VIGS[is.na(VIGS)] <- 0

VIGS_filt <- VIGS_meta[VIGS_meta$Sample_ID %in% sInfo$sampleID,]
VIGS_filt <- subset(VIGS_filt, VIGS_gene != 'EP')
VIGS_filt <- VIGS_filt[order(VIGS_filt$Sample_ID),]
rownames(VIGS_filt) <- VIGS_filt$Sample_ID
```


## ASSEMBLY ASSESSMENT FROM all_stats.tsv file in Stats directory of IMP3 output 

```{r}
library("readxl")


ass_stats <- as.data.frame(read_excel('./assemblynode_commitment.xlsx', sheet='Sheet2'))
ass_stats_samples <- ass_stats[1:54,]
ass_stats_samples <- ass_stats_samples[order(ass_stats_samples$sample),]
rownames(ass_stats_samples) <- ass_stats_samples$sample
colnames(ass_stats_samples) <- c('Sample_ID', 'N50', 'CDSs', 'KEGG_CDSs', 'seq_depth', 'dbCAN_CDSs')

ass_stats_big <- merge(VIGS, ass_stats_samples, by='Sample_ID')

ass_stats_big$VIGS_gene[ass_stats_big$VIGS_gene == 'CYP712'] <- '712'
ass_stats_big$VIGS_gene[ass_stats_big$VIGS_gene == 'CYP722'] <- '722'

ass_stats_big <- ass_stats_big[order(ass_stats_big$Sample_ID),]

```

```{r}


ggplot(data=ass_stats_big, aes(x=VIGS_gene, y=seq_depth)) +
  geom_boxplot(fill=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'), show.legend = FALSE) +
  theme(text = element_text(size=14)) +
  xlab('Treatment') +
  ylab('# of Reads')
```


##AFTER FILTERING 0s TRANSFORM DATA FOR STATISTICAL COMPARISONS 
- transform data differently for each analysis or use the same transformed data for all? chose one that is useful for all or be more exact with application of transformation?
- sum-normalization: divides each value by total sum of sample 
- hellinger-transform: samples as rows, divides each value by total of row and takes square root of value 
- CLR before PCA/for PCA 
- pseudo count the 0s 
- also to do centering and scaling, scaling is not always recommended for this data since we want to maintain the large values effect on the data analysis and comparison between the samples. 

-> transform the data, using pseudo count for the remaining 0s, then apply a PCA and plot the results to observe clusterings 
-> with the same transformed data or maybe with the separate smaller DFs perform statistical test 

```{r}
#norm and transform zero-filtered dataframe with all treatment groups

#Sum normalization 
df_few0_funct_sum <- decostand(df_few0_funct,method = "total",2)

#Hellinger transform
df_few0_funct_hellinger <- decostand(df_few0_funct,method = "hellinger",2)

#Small pseudocount of 1/10th of the smallest value bigger than zero, adding it to all values in the df
#to maintain comparable sizes between the values, then apply center-log ratio transform 
df_few0_funct_clr <- as.matrix(as.data.frame(t(clr(min(df_few0_funct[df_few0_funct>0])/10+t(df_few0_funct)))))
df_few0_funct_clr_df <- as.data.frame(t(clr(min(df_few0_funct[df_few0_funct>0])/10+t(df_few0_funct))))
#pseudocount: replacing zero values by 1 
df_few0_funct_psc <- df_few0_funct
df_few0_funct_psc[df_few0_funct_psc==0] <- 1
#then apply CLR to the dataframe 
#gems_few0groups2_clr2 <- as.matrix(as.data.frame(t(clr(t(df_few0_funct_psc)))))

```

```{r}
#plant treatments transformations and normalizations 

#Sum normalization 
df_few0_plant_sum <- decostand(df_few0_plant,method = "total",2)

#Hellinger transform
df_few0_plant_hellinger <- decostand(df_few0_plant,method = "hellinger",2)

#Small pseudocount of 1/10th of the smallest value bigger than zero, adding it to all values in the df
#to maintain comparable sizes between the values, then apply center-log ratio transform 
df_few0_plant_clr <- as.matrix(as.data.frame(t(clr(min(df_few0_plant[df_few0_plant>0])/10+t(df_few0_plant)))))

#pseudocount: replacing zero values by 1 
df_few0_plant_psc <- df_few0_plant
df_few0_plant_psc[df_few0_plant_psc==0] <- 1
#then apply CLR to the dataframe 
#gems_few0plant2_clr2 <- as.matrix(as.data.frame(t(clr(t(df_few0_plant_psc)))))

```

## Percentage of zero values in the data frames before and after filtering 

```{r}
#length of list of functional groups that have 0 value counts, divided by the total number of functional groups, multiplied by the number of samples -> approximate percentage of values in the dataset that are 0s 
length(which(df_counts==0))/(nrow(df_counts) * ncol(df_counts))

#for filtered data
length(which(df_few0_funct==0))/(nrow(df_few0_funct) * ncol(df_few0_funct))
```

## Richness and TukeyHSD test - ALL samples

**Estimated species per sample, difference in richness -> alpha diversity for each treatment group**

```{r}
#length of a list of functional groups that have counts larger than 0
richness_1_noNorm <- as.data.frame(apply(df_counts,
                           2,
                           function(x) length(which(x>0))))

summary(richness_1_noNorm)
colnames(richness_1_noNorm) <- 'Richness'
richness_1_noNorm$Treatment <- df_info$Treatment

#perform an anova for the functional groups richness in each treatment group 
richness_anova <- aov(Richness ~ Treatment, data=richness_1_noNorm)
summary(richness_anova)

#Tukey Honest Significant Differences 
#diff: difference between means of the two groups
#lwr, upr: the lower and the upper end point of the confidence interval at 95% (default)
#p adj: p-value after adjustment for the multiple comparisons.
tukey_allkegg <- TukeyHSD(richness_anova)
tukey_allkegg <- tukey_allkegg$Treatment[,c(1,4)]

#colnames(tukey_allkegg) <- c('Raw Diff', 'Raw P-adj')
tukey_allkegg

ggplot(richness_1_noNorm, aes(Treatment, Richness)) + 
  geom_boxplot(fill=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'), show.legend = FALSE) +
  theme(text = element_text(size=14)) 

#residuals versus fits plot - can be used to check the homogeneity of variances
plot(richness_anova, 1)
#no evident relationships between residuals and fitted values (the mean of each groups) ->  we can assume the homogeneity of variances
#

#Normality plot of residuals - the quantiles of the residuals are plotted against the quantiles of the normal distribution. A 45-degree reference line is also plotted
#used to check the assumption that the residuals are normally distributed. It should approximately follow a straight line.
plot(richness_anova, 2)

#plot for each treatment 
# boxplot(richness_1_noNorm ~ df_info$Treatment,
#         ylab="Number of Observed Families",
#         xlab="Tomato Lines",
#         border=c("royalblue1","tomato1","firebrick4"),
#         las=1)
```

## Richness and TukeyHSD test - filtered ALL samples

```{r}
#length of a list of functional groups that have counts larger than 0
richness_1_few0noNorm <- as.data.frame(apply(df_few0_funct,
                           2,
                           function(x) length(which(x>0))))

summary(richness_1_few0noNorm)
colnames(richness_1_few0noNorm) <- 'Richness'
richness_1_few0noNorm$Treatment <- df_info$Treatment

#perform an anova for the functional groups richness in each treatment group 
richness_few0anova <- aov(Richness ~ Treatment, data=richness_1_few0noNorm)
summary(richness_few0anova)

#Tukey Honest Significant Differences 
#diff: difference between means of the two groups
#lwr, upr: the lower and the upper end point of the confidence interval at 95% (default)
#p adj: p-value after adjustment for the multiple comparisons.
tukey_filtkegg <- TukeyHSD(richness_few0anova)
tukey_filtkegg <- tukey_filtkegg$Treatment[,c(1,4)]

#colnames(tukey_filtkegg) <- c('Filt Diff', 'Filt P-adj')
tukey_filtkegg

tukey_complete <- as.data.frame(tukey_allkegg)
df_tukey_filtkegg <- as.data.frame(tukey_filtkegg)
tukey_complete$'Filt Diff' <- df_tukey_filtkegg$`Filt Diff`
tukey_complete$'Filt P-adj' <- df_tukey_filtkegg$`Filt P-adj`
tail(tukey_complete)
tukey_complete

ggplot(richness_1_few0noNorm, aes(Treatment, Richness)) + 
  geom_boxplot(fill=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'), show.legend = FALSE) +
  theme(text = element_text(size=14))

#residuals versus fits plot - can be used to check the homogeneity of variances
plot(richness_few0anova, 1)
#no evident relationships between residuals and fitted values (the mean of each groups) ->  we can assume the homogeneity of variances
```



##PCA

```{r}
###PCA with clr data
few0_funct_pca_clr <- prcomp(t(df_few0_funct_clr))
# plot(few0_funct_pca_clr$x,
#      col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info$Treatment))], pch=19, xlab='', ylab='')
# title(ylab='PC2 (9.4%)', line=2.5, cex.lab=1.2)
# title(xlab='PC1 (15.06%)', line=2.5, cex.lab=1.2)
# legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'),
#        legend=levels(as.factor(df_info$Treatment)),
#        lty=1,
#        bty="n")

plot(few0_funct_pca_clr$x,col=alpha(c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info$Treatment))],0.7), pch=19, xlab='', ylab='', 
     cex= 16*(sqrt(VIGS$Orb_pmol_ml_g+0.0005)))
title(ylab='PC2 (9.4%)', line=2.5, cex.lab=1.2)
title(xlab='PC1 (15.06%)', line=2.5, cex.lab=1.2)
legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'),
       legend=levels(as.factor(df_info$Treatment)),
       lty=1,
      lwd=0,
       pch=16,
       bty="n")
legend("bottomright",col="grey",
       lwd=0,
       pch=16,
       title="orobanchol [pmol/ml/g]",
       pt.cex=16*(sqrt(sort(VIGS$Orb_pmol_ml_g+0.0005)))[round(seq.int(1,nrow(VIGS),length.out=5))],
       legend=round(sort(VIGS$Orb_pmol_ml_g)[round(seq.int(1,nrow(VIGS),length.out=5))],digits = 4),
       lty=1,
       bty="n")

#ggplot PCA method, but handling was not successful, percentages were taken manually from this plot
autoplot(few0_funct_pca_clr, data=t(df_few0_funct_clr), colour = rainbow(6)[as.numeric(as.factor(df_info$Treatment))]) 


#### PCA with log transformed 0 to 1 pseudocount data
# few0_funct_pca_log <- prcomp(t(log(df_few0_funct_psc)))
# plot(few0_funct_pca_log$x,
#      col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info$Treatment))],
#      main='PCA of log Transformed 1-PSC data', pch=19, xlab='PC1 (%)', ylab='PC2 (%)')
# legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'),
#        legend=levels(as.factor(df_info$Treatment)),
#        lty=1,
#        bty="n")
# 
# autoplot(few0_funct_pca_log, data=t(log(df_few0_funct_psc)), colour = rainbow(6)[as.numeric(as.factor(df_info$Treatment))], label = TRUE)
# 
# ### PCA with hellinger
# few0_funct_pca_hellinger <- prcomp(t(df_few0_funct_hellinger))
# plot(few0_funct_pca_hellinger$x,
#      col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info$Treatment))],
#      main='PCA of Hellinger Normalized data',pch=19, xlab='PC1 (%)', ylab='PC2 (%)')
# legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'),
#        legend=levels(as.factor(df_info$Treatment)),
#        lty=1,
#        bty="n")
# 
# autoplot(few0_funct_pca_hellinger, data=t(df_few0_funct_hellinger), colour = rainbow(6)[as.numeric(as.factor(df_info$Treatment))], label = TRUE)


### PCA with sum normalization 
few0_funct_pca_sum <- prcomp(t(df_few0_funct_sum))
# plot(few0_funct_pca_sum$x,
#      col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info$Treatment))], pch=19, xlab='', ylab='')
# title(ylab='PC2 (15.79%)', line=2.5, cex.lab=1.2)
# title(xlab='PC1 (52.43%)', line=2.5, cex.lab=1.2)
# legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'),
#        legend=levels(as.factor(df_info$Treatment)),
#        lty=1,
#        bty="n")


plot(few0_funct_pca_sum$x,col=alpha(c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info$Treatment))],0.7), pch=19, xlab='', ylab='', 
     cex= 16*(sqrt(VIGS$Orb_pmol_ml_g+0.0005)))
title(ylab='PC2 (15.79%)', line=2.5, cex.lab=1.2)
title(xlab='PC1 (52.43%)', line=2.5, cex.lab=1.2)
legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#5382F7', '#EBAA36', '#EA3BDC'),
       legend=levels(as.factor(df_info$Treatment)),
       lty=1,
      lwd=0,
       pch=16,
       bty="n")
legend("bottomright",col="grey",
       lwd=0,
       pch=16,
       title="orobanchol [pmol/ml/g]",
       pt.cex=16*(sqrt(sort(VIGS$Orb_pmol_ml_g+0.0005)))[round(seq.int(1,nrow(VIGS),length.out=5))],
       legend=round(sort(VIGS$Orb_pmol_ml_g)[round(seq.int(1,nrow(VIGS),length.out=5))],digits = 4),
       lty=1,
       bty="n")

#ggplot PCA method, but handling was not successful, percentages were taken manually from this plot
autoplot(few0_funct_pca_sum, data=t(df_few0_funct_sum), colour = rainbow(6)[as.numeric(as.factor(df_info$Treatment))])
```

**PLANT treatment lines PCA**

```{r}
#plant treatment groups
###PCA with clr data
few0_plant_pca_clr <- prcomp(t(df_few0_plant_clr))
# plot(few0_plant_pca_clr$x, col=c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info_plant$Treatment))], pch=19, xlab='', ylab='')
# title(ylab='PC2 (8.73%)', line=2.5, cex.lab=1.2)
# title(xlab='PC1 (13.8%)', line=2.5, cex.lab=1.2)
# legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC'),
#        legend=levels(as.factor(df_info_plant$Treatment)),
#        lty=1,
#        bty="n")

plot(few0_plant_pca_clr$x,col=alpha(c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info_plant$Treatment))],0.7), pch=19, xlab='', ylab='', 
     cex= 16*(sqrt(VIGS_filt$Orb_pmol_ml_g+0.0005)))
title(ylab='PC2 (8.73%)', line=2.5, cex.lab=1.2)
title(xlab='PC1 (13.8%)', line=2.5, cex.lab=1.2)
legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC'),
       legend=levels(as.factor(df_info_plant$Treatment)),
       lty=1,
      lwd=0,
       pch=16,
       bty="n")
legend("bottomright",col="grey",
       lwd=0,
       pch=16,
       title="orobanchol[pmol/ml/g]",
       pt.cex=16*(sqrt(sort(VIGS_filt$Orb_pmol_ml_g+0.0005)))[round(seq.int(1,nrow(VIGS_filt),length.out=5))],
       legend=round(sort(VIGS_filt$Orb_pmol_ml_g)[round(seq.int(1,nrow(VIGS_filt),length.out=5))],digits = 4),
       lty=1,
       bty="n")

#ggplot PCA method, but handling was not successful, percentages were taken manually from this plot
autoplot(few0_plant_pca_clr, data=t(df_few0_plant_clr), colour = rainbow(5)[as.numeric(as.factor(df_info_plant$Treatment))]) 

# 
# #### PCA with log transformed 0 to 1 pseudocount data
# few0_plant_pca_log <- prcomp(t(log(df_few0_plant_psc)))
# plot(few0_plant_pca_log$x,
#      col=rainbow(5)[as.numeric(as.factor(df_info_plant$Treatment))],
#      main='PCA of log transformed 1-PSC data')
# legend("topright",col=rainbow(5),
#        legend=levels(as.factor(df_info_plant$Treatment)),
#        lty=1,
#        bty="n")
# 
# autoplot(few0_plant_pca_log, data=t(df_few0_plant_psc), colour = rainbow(5)[as.numeric(as.factor(df_info_plant$Treatment))])
# 
# 
# ### PCA with hellinger 
# few0_plant_pca_hellinger <- prcomp(t(df_few0_plant_hellinger))
# plot(few0_plant_pca_hellinger$x,
#      col=rainbow(5)[as.numeric(as.factor(df_info_plant$Treatment))],
#      main='PCA of log transformed 1-PSC data')
# legend("topright",col=rainbow(5),
#        legend=levels(as.factor(df_info_plant$Treatment)),
#        lty=1,
#        bty="n")
# 
# autoplot(few0_plant_pca_hellinger, data=t(df_few0_plant_hellinger), colour = rainbow(5)[as.numeric(as.factor(df_info_plant$Treatment))])


### PCA with sum 
few0_plant_pca_sum <- prcomp(t(df_few0_plant_sum))
# plot(few0_plant_pca_sum$x,
#      col=c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info_plant$Treatment))], pch=19, xlab='', ylab='')
# title(ylab='PC2 (11.29%)', line=2.5, cex.lab=1.2)
# title(xlab='PC1 (51.69%)', line=2.5, cex.lab=1.2)
# legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC'),
#        legend=levels(as.factor(df_info_plant$Treatment)),
#        lty=1,
#        bty="n")


plot(few0_plant_pca_sum$x,col=alpha(c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC')[as.numeric(as.factor(df_info_plant$Treatment))],0.7), pch=19, xlab='', ylab='', 
     cex= 16*(sqrt(VIGS_filt$Orb_pmol_ml_g+0.0005)))
title(ylab='PC2 (11.29%)', line=2.5, cex.lab=1.2)
title(xlab='PC1 (51.69%)', line=2.5, cex.lab=1.2)
legend("topright",col=c('#EB5D5A', '#A8912E', '#51B334', '#EBAA36', '#EA3BDC'),
       legend=levels(as.factor(df_info_plant$Treatment)),
       lty=1,
      lwd=0,
       pch=16,
       bty="n")
legend("bottomright",col="grey",
       lwd=0,
       pch=16,
       title="orobanchol[pmol/ml/g]",
       pt.cex=16*(sqrt(sort(VIGS_filt$Orb_pmol_ml_g+0.0005)))[round(seq.int(1,nrow(VIGS_filt),length.out=5))],
       legend=round(sort(VIGS_filt$Orb_pmol_ml_g)[round(seq.int(1,nrow(VIGS_filt),length.out=5))],digits = 4),
       lty=1,
       bty="n")

#ggplot PCA method, but handling was not successful, percentages were taken manually from this plot
autoplot(few0_plant_pca_sum, data=t(df_few0_plant_sum), colour = rainbow(5)[as.numeric(as.factor(df_info_plant$Treatment))])


```




```{r}
#Principal Coordinate Analysis 
# pcoa1 <- pcoa(bc1)
# pcoa_val1 <- 100*c(pcoa1$values[pcoa1$values[,2]>0,2]/sum(pcoa1$values[pcoa1$values[,2]>0,2]))
# plot(pcoa1$vector[,1:2],
#      col=rainbow(6)[as.numeric(as.factor(df_info$Treatment))],
#      axes=F,
#      xlab=paste0("PC1 (",round(pcoa_val1[1],digits = 1),"%)"),
#      ylab=paste0("PC2 (",round(pcoa_val1[2],digits = 1),"%)"))
# legend("topleft",col=rainbow(6),
#        legend=levels(as.factor(df_info$Treatment)),
#        pch=1,
#        bty="n",cex=0.8)
# box()
#looks the same if applied with the funct_dist matrix 
```
## Permanova tests 

```{r}
#all samples clr transformed data permanova
permanova_clr <- adonis(t(df_few0_funct_clr) ~ Treatment,
               data = df_info, permutations=99, method = "euclidian")

# P-value
#print(as.data.frame(permanova$aov.tab)["Treatment", "Pr(>F)"])

print(as.data.frame(permanova_clr$aov.tab))

### all data sum norm data permanova
permanova_sum <- adonis(t(df_few0_funct_sum) ~ Treatment,
               data = df_info, permutations=99, method = "bray")

# P-value
#print(as.data.frame(permanova$aov.tab)["Treatment", "Pr(>F)"])

print(as.data.frame(permanova_sum$aov.tab))
```


```{r}
#plant clr transformed data permanova 
permanova_plant_clr <- adonis(t(df_few0_plant_clr) ~ Treatment,
               data = df_info_plant, permutations=99, method = "euclidian")

# P-value
#print(as.data.frame(permanova$aov.tab)["Treatment", "Pr(>F)"])

print(as.data.frame(permanova_plant_clr$aov.tab))

### plant sum norm data permanova
permanova_plant_sum <- adonis(t(df_few0_plant_sum) ~ Treatment,
               data = df_info_plant, permutations=99, method = "bray")

# P-value
#print(as.data.frame(permanova$aov.tab)["Treatment", "Pr(>F)"])

print(as.data.frame(permanova_plant_sum$aov.tab))
```



#ANCOM: Analysis of Composition of Microbiomes - Differential Abundance Testing 
```{r}
source("ancom_v2.1_noTidy.R")
```

```{r}
#df with features in rows and samples in columns
#data.frame containing the sample identifier
#sample ID name
#the group to compare
#alpha
#occurrence rate
#library size
#logistic
prepro <- feature_table_pre_process(feature_table = df_counts[rowSums(df_few0_funct[,df_info$Treatment %in% c("GUS","712")])>0,df_info$Treatment %in% c("GUS","712")], 
                                   meta_data = df_info[df_info$Treatment %in% c("GUS","712"),], 
                                   sample_var = "Sample", 
                                   group_var = "Treatment", 
                                   out_cut = 0.05, 
                                   zero_cut = 0.90, 
                                   lib_cut = 1000, 
                                   neg_lb = T)
```

```{r}
dim(df_counts) # -> 12669   54
dim(prepro$feature_table) # -> 10703   54
#number of 0s that are specific to treatment groups and does not perform further tests on these 
#not as strict as the previous filtration of zero values, could be because that is taxonomic data and this is more detailed functional group data
sum(prepro$structure_zeros) # -> 5259     dim -> 10703  6
```

```{r}
#which zeros identified in the feature table pre process were kept after zero filtering with the filter_fun function. 
which(prepro$structure_zeros %in% df_few0_funct)
#all of the structure zeros resulting from the feature table filtering were also removed from the treatment groups threshold filtering
```

```{r}
prepro_differential <- ANCOM(feature_table = prepro$feature_table,
                      meta_data = prepro$meta_data,
                      main_var = 'Treatment',
                      p_adj_method = "BH",
                      alpha = 0.05,
                      adj_formula = NULL,
                      rand_formula = NULL)
```

```{r}
prepro_differential
```



```{r}
#filter the ancom results that are significant based on the threshold used by the method
ancom_sig <- prepro_differential$out$taxa_id[prepro_differential$out$detected_0.9 == TRUE]
ancom_sig
#cutoffs on the left column and number of significant differently abundant enzymes on right
#0.6 = 50
#0.7 = 24
#0.8 = 14
#0.9 = 7 the ones showed in the volcano plot 
```



```{r}
# #DESeq2
# #df_info_712_GUS <- df_info[df_info$Treatment=='712' | df_info$Treatment=='GUS',]
# 
# df_few0_712_GUS_clr <- as.matrix(as.data.frame(t(clr(min(df_few0_712_GUS[df_few0_712_GUS>0])/10+t(df_few0_712_GUS)))))
# df_few0_712_GUS_hellinger <- decostand(df_few0_712_GUS,method = "hellinger",2)
# 
# library(DESeq2)
# 
# dds1_712_GUS <- DESeqDataSetFromMatrix(countData=df_few0_712_GUS,
#                                colData=df_info[df_info$Treatment %in% unique(df_info$Treatment)[c(1,5)],],
#                                design = ~ Treatment)
# dds1_712_GUS <- estimateSizeFactors(dds1_712_GUS)
# 
# #for visualization
# #DS_712_GUS <- counts(dds1_712_GUS,normalized=T) #DESeq2-normalized data
# #DS_712_GUS_Log <- log2(DS_712_GUS+1) 
# #boxplot(DS_712_GUS_Log)
# 
# 
# #differential analysis
# dds1_712_GUS <- DESeq(dds1_712_GUS)
# 
# #plot dispersion 
# plotDispEsts(dds1_712_GUS)
# 
# #get results
# resultsNames(dds1_712_GUS)
# res_712_GUS <- results(dds1_712_GUS, contrast=c("Treatment","712","GUS")) #these are the names of the two groups
# length(which(res_712_GUS$padj < 0.05 & !is.na(res_712_GUS$padj)))
# 
# #visualize
# plotMA(res_712_GUS, alpha=0.05)
# plotCounts(dds1_712_GUS, gene=which.min(res_712_GUS$padj), intgroup="Treatment")
# #for(i in which(res_722_GUS$padj < 0.05 & !is.na(res_712_GUS$padj))) plotCounts(dds1_712_GUS, gene=i, intgroup="Treatment")
# 
# 
# #After calling plotMA, one can use the function identify to interactively detect the row number of individual genes by clicking on the plot. One can then recover the gene identifiers by saving the resulting indices:
# 

```

```{r}
#idx <- identify(res$baseMean, res$log2FoldChange)
#rownames(res)[idx]
# plotMA(res_722_GUS, alpha=0.05)
# MMA_GUS_sig <- rownames(res_722_GUS)[which(res_722_GUS$padj<0.05)]
# sig_712_GUS <- rownames(res_712_GUS)[which(res_712_GUS$padj<0.05)]
# idx <- identify(res_712_GUS$baseMean, res_712_GUS$log2FoldChange)
# rownames(res_712_GUS)[idx]
# length(which(MMA_GUS_sig %in% sig_712_GUS))
# rownames(res_712_GUS)[which(res_712_GUS$padj<0.05)]
# length(which(res_712_GUS$padj<0.05))
```

## DESeq2

```{r}
##712-GUS
dds1_712_GUS <- DESeqDataSetFromMatrix(countData=df_few0_712_GUS,
                               colData=df_info[df_info$Treatment %in% unique(df_info$Treatment)[c(1,5)],],
                               design = ~ Treatment)
dds1_712_GUS <- estimateSizeFactors(dds1_712_GUS)

#for visualization
#DS_712_GUS <- counts(dds1_712_GUS,normalized=T) #DESeq2-normalized data
#DS_712_GUS_Log <- log2(DS_712_GUS+1) 
#boxplot(DS_712_GUS_Log)


#differential analysis
dds1_712_GUS <- DESeq(dds1_712_GUS)

#plot dispersion 
#plotDispEsts(dds1_712_GUS)

#get results
resultsNames(dds1_712_GUS)
res_712_GUS <- results(dds1_712_GUS, contrast=c("Treatment","712","GUS")) #these are the names of the two groups
length(which(res_712_GUS$padj < 0.05 & !is.na(res_712_GUS$padj)))
reslist_712_GUS <- rownames(res_712_GUS)[which(res_712_GUS$padj < 0.05 & !is.na(res_712_GUS$padj))]
reslist_712_GUS
#visualize
plotMA(res_712_GUS, alpha=0.05, colNonSig='lavender' , colSig='#EB5D5A', xlab='', ylab='')
title(ylab='logFoldChange', line=2.5, cex.lab=1.2)
title(xlab='Mean of Normalized Counts', line=2.5, cex.lab=1.2)
```

```{r}
##722-GUS
dds1_722_GUS <- DESeqDataSetFromMatrix(countData=df_few0_722_GUS,
                               colData=df_info[df_info$Treatment %in% unique(df_info$Treatment)[c(2,5)],],
                               design = ~ Treatment)
dds1_722_GUS <- estimateSizeFactors(dds1_722_GUS)

#for visualization
#DS_712_GUS <- counts(dds1_712_GUS,normalized=T) #DESeq2-normalized data
#DS_712_GUS_Log <- log2(DS_712_GUS+1) 
#boxplot(DS_712_GUS_Log)


#differential analysis
dds1_722_GUS <- DESeq(dds1_722_GUS)

#plot dispersion 
#plotDispEsts(dds1_712_GUS)

#get results
resultsNames(dds1_722_GUS)
res_722_GUS <- results(dds1_722_GUS, contrast=c("Treatment","722","GUS")) #these are the names of the two groups
length(which(res_722_GUS$padj < 0.05 & !is.na(res_722_GUS$padj)))
reslist_722_GUS <- rownames(res_722_GUS)[which(res_722_GUS$padj < 0.05 & !is.na(res_722_GUS$padj))]
reslist_722_GUS
#visualize
plotMA(res_722_GUS, alpha=0.05, colNonSig='lavender',colSig='#A8912E', xlab='', ylab='')
title(ylab='logFoldChange', line=2.5, cex.lab=1.2)
title(xlab='Mean of Normalized Counts', line=2.5, cex.lab=1.2)
```

```{r}
##CCD8-GUS
dds1_CCD8_GUS <- DESeqDataSetFromMatrix(countData=df_few0_CCD8_GUS,
                               colData=df_info[df_info$Treatment %in% unique(df_info$Treatment)[c(3,5)],],
                               design = ~ Treatment)
dds1_CCD8_GUS <- estimateSizeFactors(dds1_CCD8_GUS)

#for visualization
#DS_712_GUS <- counts(dds1_712_GUS,normalized=T) #DESeq2-normalized data
#DS_712_GUS_Log <- log2(DS_712_GUS+1) 
#boxplot(DS_712_GUS_Log)


#differential analysis
dds1_CCD8_GUS <- DESeq(dds1_CCD8_GUS)

#plot dispersion 
#plotDispEsts(dds1_712_GUS)

#get results
resultsNames(dds1_CCD8_GUS)
res_CCD8_GUS <- results(dds1_CCD8_GUS, contrast=c("Treatment","CCD8","GUS")) #these are the names of the two groups
length(which(res_CCD8_GUS$padj < 0.05 & !is.na(res_CCD8_GUS$padj)))
reslist_CCD8_GUS <- rownames(res_CCD8_GUS)[which(res_CCD8_GUS$padj < 0.05 & !is.na(res_CCD8_GUS$padj))]
reslist_CCD8_GUS
#visualize
plotMA(res_CCD8_GUS, alpha=0.05, colNonSig='lavender',colSig='#51B334', xlab='', ylab='')
title(ylab='logFoldChange', line=2.5, cex.lab=1.2)
title(xlab='Mean of Normalized Counts', line=2.5, cex.lab=1.2)
```

```{r}
##MMA-GUS
dds1_MMA_GUS <- DESeqDataSetFromMatrix(countData=df_few0_GUS_MMA,
                               colData=df_info[df_info$Treatment %in% unique(df_info$Treatment)[c(6,5)],],
                               design = ~ Treatment)
dds1_MMA_GUS <- estimateSizeFactors(dds1_MMA_GUS)

#for visualization
#DS_712_GUS <- counts(dds1_712_GUS,normalized=T) #DESeq2-normalized data
#DS_712_GUS_Log <- log2(DS_712_GUS+1) 
#boxplot(DS_712_GUS_Log)


#differential analysis
dds1_MMA_GUS <- DESeq(dds1_MMA_GUS)

#plot dispersion 
#plotDispEsts(dds1_712_GUS)

#get results
resultsNames(dds1_MMA_GUS)
res_MMA_GUS <- results(dds1_MMA_GUS, contrast=c("Treatment","MMA","GUS")) #these are the names of the two groups
length(which(res_MMA_GUS$padj < 0.05 & !is.na(res_MMA_GUS$padj)))
reslist_MMA_GUS <- rownames(res_MMA_GUS)[which(res_MMA_GUS$padj < 0.05 & !is.na(res_MMA_GUS$padj))]
reslist_MMA_GUS
#visualize
plotMA(res_MMA_GUS, alpha=0.05, colNonSig='lavender',colSig='#EA3BDC', xlab='', ylab='')
title(ylab='logFoldChange', line=2.5, cex.lab=1.2)
title(xlab='Mean of Normalized Counts', line=2.5, cex.lab=1.2)
```





### Maaslin2 analysis 

```{r}
library(Maaslin2)
#MaAsLin2 requires two input files, one for taxonomic or functional feature abundances, and one for sample metadata.
#Microbiome Multivariable Association with Linear Models

ko <- read.delim("dbCAN_profile.csv",sep=",",row.names=1)
ko[is.na(ko)] <- 0

summary(colSums(ko))

sInfo <- data.frame("sampleID"=colnames(ko))
sInfo$group <- gsub("_[^_]+$","",sInfo$sampleID)
sInfo <- sInfo[order(rownames(sInfo)),]
ko <- ko[,order(colnames(ko))]

ko_T <- ko[,sInfo$group %in% c("T_GUS","T_712","T_CCD8","T_722")]
ko_T <- ko_T[rowSums(ko_T)>0,]

sInfo_T <- sInfo[sInfo$group %in% c("T_GUS","T_712","T_CCD8","T_722"),]

ko_T712 <- ko[,sInfo$group %in% c("T_GUS","T_712")]
ko_T712 <- ko_T712[rowSums(ko_T712)>0,]

sInfo_T712 <- sInfo[sInfo$group %in% c("T_GUS","T_712"),]
rownames(sInfo_T712) <- sInfo_T712$sampleID

rownames(sInfo) <- sInfo$sampleID

MSLfilt_712_clrlm = Maaslin2(
input_data = t(df_few0_712_GUS),
input_metadata = sInfo_T712,
min_prevalence = 0,
transform = "NONE",
normalization = "CLR",
analysis_method = "LM",
output = "dbcan_clrlm",
fixed_effects = c("group"),
reference = c("T_GUS"))


# MSLfilt_712_nb = Maaslin2(
# input_data = t(df_few0_712_GUS),
# input_metadata = sInfo_T712,
# min_prevalence = 0,
# transform = "NONE",
# normalization = "NONE",
# analysis_method = "NEGBIN",
# output = "filtered_output_nb",
# fixed_effects = c("group"),
# reference = c("T_GUS"))
# 
# 
# MSLfilt_712_loglm = Maaslin2(
# input_data = t(df_few0_712_GUS),
# input_metadata = sInfo_T712,
# min_prevalence = 0,
# transform = "LOG",
# normalization = "CSS",
# analysis_method = "LM",
# output = "filtered_output_loglm",
# fixed_effects = c("group"),
# reference = c("T_GUS"))


MSLfilt_712_cssnb = Maaslin2(
input_data = t(df_few0_712_GUS),
input_metadata = sInfo_T712,
min_prevalence = 0,
transform = "NONE",
normalization = "CSS",
analysis_method = "NEGBIN",
output = "dbcan_cssnbn",
fixed_effects = c("group"),
reference = c("T_GUS"))


#methods comparison to observe overlap between the found differentially abundant enzymes

MSLclrlm_712 <- MSLfilt_712_clrlm$results$feature[which(MSLfilt_712_clrlm$results$pval<0.05)] #148
MSLcssnb_712 <- MSLfilt_712_cssnb$results$feature[which(MSLfilt_712_cssnb$results$pval<0.05)] #117

MSLfilt_712_clrlm$results$feature[which(MSLclrlm_712 %in% dds1_712_GUS_res)] #102 of 105
MSLfilt_712_cssnb$results$feature[which(MSLcssnb_712 %in% dds1_712_GUS_res)] #89 

#MSLcssnb_712

ancom_sig[which(ancom_sig %in% dds1_712_GUS_res)] #"CBM59.hmm" "PL1_4.hmm"
ancom_MSL_sigs <- MSLfilt_712_clrlm$results$feature[which(MSLclrlm_712 %in% ancom_sig)]
MSLfilt_712_cssnb$results$feature[which(MSLcssnb_712 %in% ancom_sig)] #"GH45.hmm"  "PL1_4.hmm" "CBM59.hmm"

ancom_MSL_sigs[which(ancom_MSL_sigs %in% dds1_712_GUS_res)]

```



```{r}
# resultsNames(dds1_712_GUS)
# res_712_GUS <- results(dds1_712_GUS, contrast=c("Treatment","712","GUS")) #these are the names of the two groups
# length(which(res_712_GUS$padj < 0.05 & !is.na(res_712_GUS$padj)))
# dds1_712_GUS_res <- rownames(res_712_GUS)[which(res_712_GUS$padj<0.05)]
# 
# 
# 
# #visualize
# plotMA(res_712_GUS, alpha=0.05)
# plotCounts(dds1_712_GUS, gene=which.min(res_712_GUS$padj), intgroup="Treatment")
# #for(i in which(res_722_GUS$padj < 0.05 & !is.na(res_712_GUS$padj))) plotCounts(dds1_712_GUS, gene=i, intgroup="Treatment")
# 
# 
# #After calling plotMA, one can use the function identify to interactively detect the row number of individual genes by clicking on the plot. One can then recover the gene identifiers by saving the resulting indices:
# 
# #idx <- identify(res$baseMean, res$log2FoldChange)
# #rownames(res)[idx]
# plotMA(res_722_GUS, alpha=0.05)
# MMA_GUS_sig <- rownames(res_722_GUS)[which(res_722_GUS$padj<0.05)]
# sig_712_GUS <- rownames(res_712_GUS)[which(res_712_GUS$padj<0.05)]
# idx <- identify(res_712_GUS$baseMean, res_712_GUS$log2FoldChange)
# rownames(res_712_GUS)[idx]
# length(which(MMA_GUS_sig %in% sig_712_GUS))
# rownames(res_712_GUS)[which(res_712_GUS$padj<0.05)]
# length(which(res_712_GUS$padj<0.05))
```



```{r}
ggplot(MSLfilt_712_clrlm$results, aes(y=-log10(pval), x=coef, color=qval<0.05 & (coef>1 | coef< -1))) + 
  geom_point() 
```


```{r}
ggplot(MSLfilt_712_cssnb$results, aes(y=-log10(pval), x=coef, color=qval<0.05 & (coef>1 | coef< -1))) + 
  geom_point() 
```




## Further Explorative Analysis 
- can uncomment some things if interested in running them 

```{r}
#

# df_few0_712_GUS_clr <- as.matrix(as.data.frame(t(clr(min(df_few0_712_GUS[df_few0_712_GUS>0])/10+t(df_few0_712_GUS)))))
# df_info_712_GUS <- df_info[df_info$Treatment=='712' | df_info$Treatment=='GUS',]
# 
# # perform permanova for analysis along side PCA
# permanova_712_GUS <- adonis(t(df_few0_712_GUS_clr) ~ Treatment,
#                data = df_info_712_GUS, permutations=99, method = "euclidian")
# 
# # P-value
# #print(as.data.frame(permanova_712_GUS$aov.tab)["Treatment", "Pr(>F)"])
# 
# print(as.data.frame(permanova_712_GUS$aov.tab))
```

```{r}
#df_new <- pivot_longer(df,names_to="treatment",values_to="counts", -X )

#split based on sample name pattern, keeping all but the T from the sample name, into 2 new columns with the specified names
#df_new <- separate(df_new, treatment, into=c('t','treatment','sample'), sep='[_]') %>% select(!t)
df_few0_712_GUS_clr <- setDT(as.data.frame(df_few0_712_GUS_clr), keep.rownames = "X")
#colnames(df_few0_712_GUS_clr)[0] <- 'X'
df_712_GUS_long <- pivot_longer(df_few0_712_GUS_clr,names_to="Sample",values_to="Counts", -X)

#split based on sample name pattern, keeping all but the T from the sample name, into 2 new columns with the specified names
df_712_GUS_long <- separate(df_712_GUS_long, Sample, into=c('t','Treatment','Sample'), sep='[_]') %>% select(!t)

#anova
# model <- lm(X~Treatment, df_712_GUS_long)
#making this model is not useful because i was trying to model what the data is actually doing. an effect on the functional groups between the treatments. maybe stick to doing the functional groups individually between the treatments or doing the ancom which automatically considers all of the functional groups as features between the treatments. 
```


compare the controls with each other to observe transformation effect on the plant, just in general, is this a validation of controls? 
compare each experimental line with the each control
- perform statistical tests between the treatment groups and controls to determine the functional groups with low p values (graphical representation of the functional group counts between the compared groups -> )
-should be making linear or non-linear models for the relation between the groups to observe coefficients? what is the purpose of these? should they be used to observe residuals?? 
-

graphical outputs
GENERAL COMPARISON - functional composition 
-data presentation: boxplot figure with number of functional groups found in each treatment group and how they compared between the groups.
-PCA of samples with colors for treatments for validation (on the raw and transformed data to compare the explained variation and observe the effect of outliers)
-show residuals? and how to interpret
-peak profile with a control on background showing the average normal counts found, and then the average found for each of the treatment types for those functional groups that were significantly different, maybe include some confidence interval bars to show the difference of counts graphically (this can be done with filtering of the functional groups that were found to be significantly different by evaluating the pvalue) 

PAIRWISE COMPARISON
-heatmap? comparing between 2 types of treatments at a time (so 3, and then a 4th comparing all 3 experimental treatments to the base control) making a 4 heatmap figure to also compare between each other


```{r}
par(mfrow=c(2,2))

#total mapped reads per sample - depth 
col_counts <- as.data.frame(colSums(df_counts))
colnames(col_counts) <- c("Total_mapped_Reads")
#Plot of total mapped counts per sample 
plot(col_counts$`Total_mapped_Reads`, ylab = 'Total Mapped Reads', xlab = 'Sample', xlim = c(0,55), ylim = c(25000000,40000000), col =rainbow(6)[as.numeric(as.factor(df_info$Treatment))])

plot(colSums(df_few0_funct_clr), main= "CLR", col=rainbow(6)[as.numeric(as.factor(df_info$Treatment))])

plot(colSums(df_few0_funct_sum), main ="SUM", col=rainbow(6)[as.numeric(as.factor(df_info$Treatment))])

plot(colSums(df_few0_funct_hellinger), main="hellinger", col=rainbow(6)[as.numeric(as.factor(df_info$Treatment))])
```

```{r}
par(mfrow=c(2,2))
#COUNTS PER SAMPLE
#distribution of total mapped counts per sample, showing that most of the samples have a total count at 35,000,000
hist(col_counts[,1],xlab="Total Counts per Sample",main="Histogram of Total Mapped Counts Distribution",las=1)
hist(colSums(df_few0_funct_clr),xlab="Total Counts per Sample",main="Histogram of CLR Mapped Counts Distribution",las=1)
hist(colSums(df_few0_funct_sum),xlab="Total Counts per Sample",main="Histogram of SUM Mapped Counts Distribution",las=1)
hist(colSums(df_few0_funct_hellinger),xlab="Total Counts per Sample",main="Histogram of Hellinger Mapped Counts Distribution",las=1)

```


```{r}
#ggplot(df_counts) +  
  #geom_boxplot(aes(x=T_712_11))
par(mfrow=c(2,2))

#Plot of distribution of counts for all functional profiles, per sample. Showing basically only the outliers since the data is heavily skewed
boxplot(df_counts, col = rainbow(6)[as.numeric(as.factor(df_info$Treatment))])
#
boxplot(df_few0_funct_clr, col = rainbow(6)[as.numeric(as.factor(df_info$Treatment))])

boxplot(df_few0_funct_sum, col = rainbow(6)[as.numeric(as.factor(df_info$Treatment))])

boxplot(df_few0_funct_hellinger, col = rainbow(6)[as.numeric(as.factor(df_info$Treatment))])

```

```{r}
#pseudo count replace 0 values for 1 
df_counts_1 <- replace(df_counts, df_counts==0, 1)
#plot the distribution of all mapped counts per sample on a logarithmic scale
boxplot(log(df_counts_1), col = c("royalblue1","tomato1","firebrick4","yellow","purple","green")[as.numeric(as.factor(df_info$Treatment))])

#sample 31, which is T_CCD8_8 has a different boxplot compared to the rest 
```


Perform a rarefaction analysis.

```{r}
rarecurve(as.data.frame(t(df_counts)), step=1000000, label = FALSE, ylim= c(7000,10000), xlim = c(5000000, 40000000), cex=0.6,
#quickRareCurve(as.data.frame(t(df_counts)), max.cores = F, nCores = 6)
          col = c("royalblue1","tomato1","firebrick4","yellow","purple","green")[as.numeric(as.factor(df_info$Treatment))])
abline(v=min(colSums(df_counts)),lty=3)
legend("bottomright",col=c("royalblue1","tomato1","firebrick4","yellow","purple","green"),
       legend=levels(as.factor(df_info$Treatment)),
       lty=1,
       bty="n")
```



```{r}
#count number of 0s per column
colSums(df_counts==0)
```



We can observe that even though samples from the 712 group have the lowest mapped read counts the number of functional groups/families are not affected as they seem to be quite well distributed compared to the other types of samples. The EmptyPot group has the highest number of functional groups mapped, which is expected and good confirmation of the data. 

In how many samples are the functional groups observed?

```{r}
#maybe, completeness of dataset
hist(apply(df_counts,
           1,
           function(x) 100*length(which(x>0))/length(x)),
     xlab="% samples with species",main="",las=1,breaks=20)
```

```{r}
#get the index of the functional group with the max value count for the first sample
maxx <- which.max(df_counts[,1])
#what is the value count and the name of the functional group for the first sample
cat(df_counts[maxx,1], rownames(df_counts[maxx,]))
#get the index of the functional group with the max calue for each of the samples
apply(df_counts,2,which.max)
```

All the samples have the same family as their highest mapped read count, which is: 

```{r}
#get the max value functional group for all the samples
#print the name of the functional groups 
#print the value 
for (i in 1:ncol(df_counts))
{
  maxx <- which.max(df_counts[,i])
  #print(df_counts[[maxx]])
  print(names(df_counts)[i])
  cat(colnames(df_counts[,i]), df_counts[maxx,i], rownames(df_counts[maxx,]), "\n")
}

```







```{r}
#sets functional groups columns as X
df = read.csv("dbCAN_profile.csv")

#gather specific original columns to new columns except the X where the functional groups are, names_to contains original column names, values_to will contain entries from the original columns  
df_new <- pivot_longer(df,names_to="treatment",values_to="counts", -X )

#split based on sample name pattern, keeping all but the T from the sample name, into 2 new columns with the specified names
df_new <- separate(df_new, treatment, into=c('t','treatment','sample'), sep='[_]') %>% select(!t)
#replace pseudo count zeros to 1
df_new$counts[df_new$counts == 0] <- 1
#boxplot with mapped counts plotted as a function of treatment. 
boxplot(counts~treatment, data=df_new, col='grey')

#boxplot with logarith of mapped counts plotted as a function of treatment. previous 0 values are not included as the log function cannot be applied to them
boxplot(log(counts)~treatment, data=df_new, col='grey')

```


```{r}
data <- as.matrix(df_counts)
heatmap(data)

#scaling on row and column bases, column most useful since we need to capture variation between columns
heatmap(data, scale = 'row')
#scaling by column doesn't do anything

heatmap(data, scale = 'column')
#scaling by column doesn't show anything, don't know why

#heatmap() reorders both variables and observations using a clustering algorithm: it computes the distance between each pair of rows and columns and try to order them by similarity.

#cluster <- agnes(df_counts$T_MMA_12, diss = TRUE, method = "average")
#plot(cluster, which.plots = 2, hang = -1, label = sample, main = "", axes = FALSE, xlab = "", ylab = "", sub = "")
#heatmap(df_counts$T_MMA_12, scale = "none")
```


```{r}
heatmap(data, Colv = NA)
```


## Normalization 
- different genes and genomes come in different sizes, which means that at equal coverage, the number of mapped reads to a certain gene or region will be directly dependent on the length of that region (the latter scenario is not a huge issue for Pfam families)
- the interesting changes in bacterial composition might be drowned by genetic material from the host plant. That will then have a huge impact on the gene abundances of the bacteria, even if those abundances are actually the same. The same applies to complex microbial communities with both bacteria, single-cell eukaryotes and viruses. In such cases, it might be better to consider a normalization to the number of bacteria in the sample (or eukaryotes if that is what you want to study). One way of doing that is to count the number of reads mapping to the 16S rRNA gene in each sample. You can then divide each gene count with the number of 16S rRNA counts, to yield a genes per 16S proportion: (counts of gene X / counts of 16S rRNA gene)



